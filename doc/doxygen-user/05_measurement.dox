/** @page measurement Application Measurement
\seclabel{measurement}

If an application was instrumented with @scorep, you will get an executable, which
you can execute like the uninstrumented application. After the application run, you
will find an experiment directory in your current working directory, which contains
all recorded data. The experiment directory has the format
<tt>scorep-YYYYMMDD_HHMM_XXXXXXXX</tt>, where <tt>YYYYMMDD</tt> and <tt>HHMM</tt> encodes
the date followed by a series of random numbers. You may specify the name of the
experiment directory by setting the environment variable \confvar{SCOREP_EXPERIMENT_DIRECTORY}
to the desired name of the directory. If the directory already exists, the existing
directory will be renamed by appending a date like above by default. You can let
@scorep abort the measurement immediately by setting \confvar{SCOREP_OVERWRITE_EXPERIMENT_DIRECTORY}
to <tt>false</tt> if the experiment directory already exists. This has only an
effect if \confvar{SCOREP_EXPERIMENT_DIRECTORY} was set too.

In general, you can record a profile and/or a event trace. Whether a profile and/or a
trace is recorded, is specified by the environment variables
\confvar{SCOREP_ENABLE_PROFILING} and \confvar{SCOREP_ENABLE_TRACING}. If the value of this
variables is zero or <tt>false</tt>, profiling/tracing is disabled.
Otherwise @scorep will record a profile and/or trace. By default, profiling is enabled and tracing
is disabled.

You may start with a profiling run, because of its lower space requirements. According
to profiling results, you may configure the trace buffer limits, filtering or selective
recording for recording traces.

@scorep allows to configure several parameters via environment variables.
See Appendix @secref{scorepmeasurementconfig} for a detailed description of how
to configure the measurement.

@section profiling Profiling
@seclabel{profiling}

@scorep implements a call-tree based profiling system. Every node in the call tree
represent a recorded region. The edges of the tree represent the caller-callee
relationship: The children of a node are those regions, that are entered/exited within
a region. The path from the root to an arbitrary node, represents a call-path. Thus,
every node in the tree identifies also the call-path from the root to itself.

Together with a node, the statistics for the call-path are stored.
By default, the runtime and the number of visits are recorded. Additionally, hardware
counters can be configured and are stored for every call-path. User defined metrics
are only stored in those nodes, where the metric was triggered.

For enabling profiling, set the  \confvar{SCOREP_ENABLE_PROFILING} environment variable
to 1 or <tt>true</tt>. After the execution of your application you will then find
a file, named <tt>profile.cubex</tt> in your measurement directory, which you can display
with the @cube4 with <tt>cube-qt profile.cubex</tt>. The name of the profile can be
changed through the environment variable \confvar{SCOREP_PROFILING_BASE_NAME}. The
extension <tt>.cubex</tt> will be appended to the base name you specify in the
environment variable \confvar{SCOREP_PROFILING_BASE_NAME}.

By default, @scorep writes the profile in @cube4 base format. Hereby, for every metric
contains one value, usually only the sum. However, @scorep allows to store the profile
in two other formats. To change the default format, set the environment variable
\confvar{SCOREP_PROFILING_FORMAT}. Please refer to the description of this variable for
possible values.

@scorep records a call tree profile. The maximum call-path depth that is recorded
is limited to 30, by default. This avoids
extremely large profiles for recursive calls. However, this limit can be changed with
the environment variable \confvar{SCOREP_PROFILING_MAX_CALLPATH_DEPTH}.


@subsection parameter_profiling Parameter-Based Profiling
@seclabel{parameter_profiling}

Parameter-based profiling allows to separate the recoded statistics for a region,
depending on the values of one or multiple parameters. In the resulting call-tree,
each occurred parameter-value will create a sub-node of the region. Every parameter has
a parameter name. Thus, if multiple parameters are used, they can be distinguished and
split the call-tree in the order of the parameter events. In the final call-tree it
looks like every parameter-name/parameter-value pair is a separate region.

Currently, the only source for parameter events is manual instrumentation
(see Section @secref{parameter_instrumentation}).


@subsection phase_profiling Phase Profiling
@seclabel{phase_profiling}

Phase-profiling allows, to group the execution of the application into logical phases.
@scorep records a separate call-tree for every phase in the application. A phase starts
when a region of type <tt>SCOREP_USER_REGION_TYPE_PHASE</tt>
(see Section @secref{manual_instrumentation}) is entered. If the region is exited,
the phase
is left. If two phases are nested, then the outer phase is left, when the inner phase is
entered. If the inner phase is exited, the outer phase is re-entered.
Figure @figref{PhaseProfiling} shows the difference in the call-tree if the regions
with the names phase1 and phase2 are not of type
<tt>SCOREP_USER_REGION_TYPE_PHASE</tt> on the left side and the forest if they are of
type <tt>SCOREP_USER_REGION_TYPE_PHASE</tt> on the right side.

@img{phase_profiling,PhaseProfiling,Call-tree changes when using phases. The left
side shows the calltree if no region is of type phase. The right side shows the
call-tree forest with phases., width=0.9\textwidth}

If the phase consists of multiple partitions, and thus cannot be enclosed by a single
code region, all code-regions that form the phase must have the same region handle.
The possibility to define global region handles in C/C++ might be useful for the
definition of phases that are have multiple partitions
(see Section @secref{manual_instrumentation}).


@subsection dynamic_profiling Dynamic Region Profiling
@seclabel{dynamic_profiling}

When profiling, multiple visits of a call-path are summarized. However, e.g, for
investigations in time-dependent behavior of an application, each iteration of
a main loop (or some other region) should create a separate profile sub-tree.
For such cases, @scorep allows to define regions to by of type dynamic. For dynamic
regions, each entry of the region will create a separate path. For this cause, the
@scorep profiling system creates an extra parameter, named <tt>instance</tt>. On each
visit to a dynamic region, the instance parameter for this call-path is increased
and triggered automatically. Thus, the every visit to a dynamic region generates a
separate subtree in the profile.

As an example, let us assume that an application contains the regions <tt>foo</tt> and
<tt>main</tt>, where <tt>main</tt> calls <tt>foo</tt> three times. A regular profile
would show two call-pathes:
<ul>
  <li><tt>main</tt></li>
  <li><tt>main/foo</tt></li>
</ul>
If <tt>foo</tt> is a dynamic region, the profile would contain additional sub-nodes for
each visit of <tt>foo</tt>. The resulting profile would contain the following
call-pathes:
<ul>
  <li><tt>main</tt></li>
  <li><tt>main/foo</tt></li>
  <li><tt>main/foo/instance=0</tt></li>
  <li><tt>main/foo/instance=1</tt></li>
  <li><tt>main/foo/instance=2</tt></li>
</ul>

In this case <tt>main/foo</tt> contains the summarized statistics for all 3 visits, while
<tt>main/foo/instance=0</tt> contains the statistics for the first visits of the call-path.

@note The enumeration of the instance is per call-path and not per dynamic region.
      In particular, if a dynamic region foo appears in 2 call-paths, it has 2
      instance number 0, one in both call-paths. It is not a global enumeration of
      the visits to foo but enumerates the visits of foo in a particular call-path from
      0 to N.

Currently, the only possibility to define dynamic regions is via the manual region
instrumentation, described in Section @secref{manual_instrumentation}.


@note Using dynamic regions can easily create very large profiles. Thus, use this
      feature with care. If you are only interested in some parts of the application,
      selective recording (see Section @secref{selective_recording}) might be a memory
      space save alternative. Furthermore, you can use clustering
      (see Section @secref{clustering}) to reduce the memory requirements.


@subsection clustering Clustering
@seclabel{clustering}

Clustering allows to reduce the memory requirements of a dynamic region, by clustering
similar sub-trees into one cluster. A visualization tool (like CUBE 4) might expand
the clusters back to single iterations transparently. You can enable/disable
clustering via the environment variable \confvar{SCOREP_PROFILING_ENABLE_CLUSTERING}.
By default, clustering is enabled.

Currently, clustering is limited to the instances of one node in the
call-tree. If a dynamic region appears on several call-paths, @scorep will only
cluster one, and generate separate sub-trees for every iterations in all other
call-paths. By default, @scorep will cluster the instances of that dynamic region
call-path that it enters first. If you have only one call-path where a dynamic region
occurs (e.g., if the body of the main loop is the only dynamic region), this
region will be clustered automatically. Otherwise, we recommend to specify
the region you want to cluster in the environment variable
\confvar{SCOREP_PROFILING_CLUSTERED_REGION}.

@note If the selected region appears on multiple call-paths, only one of them
      is clustered. @scorep chooses the call-path of that regions that it enters first.
      In particular, if the selected dynamic region is nested into itself, the
      outermost occurrence is clustered.

Furthermore, the clustered region must not be inside of a parallel region, but must
be at a sequential part of the program. However, the clustered region may contain
parallel regions.

Clustering is a lossy compression mechanism. The accuracy increases if more clusters
are available. On the downside, more clusters require more memory. You can
specify the number of clusters you want by setting the environment variable
\confvar{SCOREP_PROFILING_CLUSTER_COUNT} to the number of cluster you want to have.
The default cluster number is 64.

Furthermore, you can enforce a minimal structural similarity of instances of a cluster.
Clusters that fit the minimal structural similarity requirements belong to the
same equivalence class. Only instances of the same equivalence class will be clustered
together. If you have more equivalence classes than the number of clusters you specified
in \confvar{SCOREP_PROFILING_CLUSTER_COUNT}, the maximal number of clusters is
increased. Thus, you might get more clusters than you specified.

The minimal structural similarity is defined by the clustering mode which can be set
via the environment variable \confvar{SCOREP_PROFILING_CLUSTERING_MODE}. Please refer to the
description of this variable for possible values.

@subsection profile_debug_output Enabling additional debug output on inconsistent profiles
@seclabel{profile_debug_output}

If the @scorep profiling system detects inconsistencies during measurement, it stops
recording the profile and prints an error message. Examples for reasons of an
inconsistent profile are, if the nesting order of function entries and exits is
broken, or events appear for an uninitialized thread. This might indicate an bug
of the profile, but typically the cause is an erroneous instrumentation. E.g. if
manual instrumentation is applied, but not all possible exit points of a function
are instrumented.

In order to support debugging of manual instrumentation, or during the development
of own automatic instrumentation techniques, the profile can write additional
information about its current state in a textual form into a file. This output
may contain the following information:
<ul>
 <li> The current call stack of the failing thread </li>
 <li> The profile structure of the failing thread </li>
 <li> The complete profile structure </li>
</ul>
None of the three entries is guaranteed to appear in the output, it depends on
the current state of the profile. It might not be possible to provide any
output at all. Furthermore, the online representation of the profile structure may
differ from the final profile structure.

You can enable this additional output by setting the environment variable
\confvar{SCOREP_PROFILING_ENABLE_CORE_FILES} to <tt>true</tt>. Then, if the
profile detects an inconsistency, it will write a core file into
your measurement directory. If an inconstant profiles is detected on multiple
locations, every location where an inconsistency is detected will write a
core file. Thus, it is not recommended, to enable this feature for large scale runs.


@section tracing Tracing
@seclabel{tracing}

@scorep can write events to OTF2 traces. By setting the environment variable
\confvar{SCOREP_ENABLE_TRACING}, you can control whether a trace is recorded. If the
value is <tt>0</tt> or <tt>false</tt> no trace is recorded, if the value is non-zero
or <tt>true</tt>, a trace is recorded. If the variable is not specified,
@scorep records traces on default.
After trace recording you will find the OTF2 anchor file, named <tt>trace.otf2</tt>
in the experiment directory, along with the trace data.



@section filtering Filtering
@seclabel{filtering}

When automatic compiler instrumentation or automated source code instrumentation with
PDT has been used to instrument user-level source-program routines, there
are cases where measurement and associated analysis are degraded,
e.g., by frequently-executed, small and/or generally uninteresting
functions, methods and subroutines.

A measurement filtering capability is therefore only supported for compiler
instrumented regions, regions instrumented with the user API from @scorep (see
section @secref{manual_instrumentation}), regions instrumented with the user API
from @opari2 (see section @secref{pomp_instrumentation}), and CUDA device and host
activities (see Section @secref{cuda_adapter}). See section @secref{mpi_groups}
to restrict the recording of @mpi features and the @opari2 documentation of
<tt>--disable</tt> to restrict instrumentation of @openmp directives. This
<tt>--disable</tt> flag can than be passed on to the @opari2 invocation with the
<tt>--opari=<parameter-list></tt> flag of the @scorep instrumenter.
Because PDT instrumentation (Section @secref{tau_instrumentation}) inserts
@scorep user API instrumentation those regions can be filtered, too.
Regions can be filtered based on their region name (e.g., their function name)
or based on the source file, in which they are defined.

A file that contains the filter definition can be specified via the environment
variable \confvar{SCOREP_FILTERING_FILE}. If no filter definition file is specified,
all instrumented regions are recorded. For filtered regions, the enter/exit events
are not recorded in trace and profile.

The filter definition file can contain two blocks:
<ul>
  <li> One block defines filter rules for filtering regions based on the source files
       they are defined in.
  </li>
  <li> One filter block defined rules for region names.
  </li>
</ul>

When the filter rules are applied, the source file name filter is evaluated first. If
a region is filtered because it appears in a filtered source file, it cannot be included
by the function name filter. If a region was defined in a not-filtered source file,
the region name filter is evaluated. This means, events for a region are not recorded
if they are filtered by the source file filter or the region name filter. Events for
a region are recorded if the region is neither filtered by the source file filter nor
by the region name filter. If one of the both filter blocks is not specified, it is
equivalent to an empty filter block.

Beside the two filter blocks, you may use comments in the filter definition file.
Comments start with the character '#' and is terminated by a new line.
You may use comments also inside the filter blocks. If a region name or source file
name contains '#', you must escape it with a backslash.

@subsection source_filtering Source File Name Filter Block
@seclabel{source_filtering}

The filter block for source file names, must be enclosed by
<tt>SCOREP_FILE_NAMES_BEGIN</tt> and <tt>SCOREP_FILE_NAMES_END</tt>. In between you
can specify an arbitrary number of include and exclude rules which are evaluated in
sequential order. At the beginning all source files are included. Source files that
are excluded after all rules are evaluated, are filtered.

An exclude rule starts with the keyword <tt>EXCLUDE</tt> followed by
one or multiple white-space separated source file names.
Respectively, include rules start with <tt>INCLUDE</tt>
followed by one or multiple white-space separated file names. For the specification of
file names, bash-like wild-cards are supported. In particular, the '*' wild-card
matches an string of arbitrary length, the '?' matches exactly one arbitrary
character, or within `[]` you may specify multiple options.

@note Unlike bash, a '*' may match a string that contains slashes. E.g, you may
      use the '*' wild-card for path prefixes.

An example source file filter block could look like this:
@code
SCOREP_FILE_NAMES_BEGIN # This is a comment
  EXCLUDE */filtering/filter*
  INCLUDE */filter_test.c
SCOREP_FILE_NAMES_END
@endcode

@note The keywords (<tt>SCOREP_FILE_NAMES_BEGIN</tt>,
      <tt>SCOREP_FILE_NAMES_END</tt>, <tt>EXCLUDE</tt>, and <tt>INCLUDE</tt>) are
      case-sensitive.

The filtering is based on the filenames as seen by the measurement system.
Depending on instrumentation method and compiler the actual filename may
contain the absolute path, a relative path or no path at all. The instrumentation
tool tries to create as much absolute paths as possible. Paths are
simplified before comparison to a rule. E.g. it removes <tt>path/../</tt>,
<tt>/./</tt> and multiple slashes. You may look up the actual filename in the resulting
output of the measurement.


@subsection region_filtering Region Name Filter Block
@seclabel{region_filtering}

The filter block for the region names, must be enclosed by
<tt>SCOREP_REGION_NAMES_BEGIN</tt> and <tt>SCOREP_REGION_NAMES_END</tt>. In between you
can specify an arbitrary number of include and exclude rules which are evaluated in
sequential order. At the beginning, all regions are included. Regions that
are excluded after all rules are evaluated, are filtered.

@note Regions that are defined in source files that are filtered, are excluded
      due to the source file filter. They cannot be included anymore by an
      include rule in the region filter block.

An exclude rule starts with the keyword <tt>EXCLUDE</tt> followed by
one or multiple white-space separated region names.
Respectively, include rules start with <tt>INCLUDE</tt>
followed by one or multiple white-space separated expressions. For the specification of
region names, bash-like wild-cards are supported. In particular, the '*' wild card
matches an string of arbitrary length, the '?' matches exactly one arbitrary
character, or within `[]` you may specify multiple options.


An example region filter block could look like this:
@code
SCOREP_REGION_NAMES_BEGIN
  EXCLUDE *
  INCLUDE bar foo
          baz
          main
SCOREP_REGION_NAMES_END
@endcode

In this example, all but the functions bar, foo, baz and main are filtered.

The filtering is based on the region names as seen by the measurement system.
Depending on instrumentation method and compiler the actual region name may
be mangled, or decorated. Thus, you may want to inspect
the profile to determine the name of a region inside the measurement system.

In some cases, the instrumentation provides mangled names, which are demangled
by Score-P. In this cases, Score-P uses the demangled form for display in profile and
trace definitions, and thus, the demangled form should be used in the filter
file. However, The <tt>MANGLED</tt> keyword marks a filter rule to be applied
on the mangled name, if a different
mangled name is available. If no mangled name is available, the rule is applied on
the displayed name instead. The <tt>MANGLED</tt> keyword must appear inside of an
include rule or exclude rule. All patterns of the rule that follow the
<tt>MANGLED</tt> keyword, are applied to the mangled name, if the mangled
name is available.


In the following example, foo and baz are applied to the mangled name,
while bar and main are applied on the displayed name.
@code
SCOREP_REGION_NAMES_BEGIN
  EXCLUDE *
  INCLUDE bar MANGLED foo
          baz
  INCLUDE main
SCOREP_REGION_NAMES_END
@endcode

The displayed name may also be mangled if no demangled form is available. It is
not necessary to prepend rules with the <tt>MANGLED</tt> keyword if the
displayed name is mangled, but only if a mangled name is available that differs
from the displayed name.

@note The keywords (e.g., <tt>EXCLUDE</tt>, <tt>INCLUDE</tt>,
      <tt>SCOREP_REGION_NAMES_BEGIN</tt>, <tt>SCOREP_REGION_NAMES_END</tt>,
      and <tt>MANGLED</tt> are case-sensitive.

@note
  The GCC plug-in based function instrumentation supports all above mentioned
  filtering features when using the @verb{--instrument-filter} flag to the
  @scorep instrumenter (see Sec. @secref{compiler_instrumentation}).
  The filter file is then used during compilation time but the use of such a filter file
  during runtime is still possible. The usage of the filter during compilation time
  removes the overhead of runtime filtering.

@section selective_recording Selective Recording
@seclabel{selective_recording}

@scorep experiments record by default all events during the whole execution run.
If tracing is enabled the event data will be collected in buffers on each process
that must be adequately sized to store events from the entire execution.

Instrumented routines which are executed frequently, while only performing a
small amount of work each time they are called, have an undesirable impact on
measurement. The measurement overhead for such routines is large in
comparison to the execution time of the uninstrumented routine, resulting in
measurement dilation. Recording these events requires significant space and
analysis takes longer with relatively little improvement in quality.
Filtering can be employed during measurement (described in Section @secref{filtering}) to
ignore events from compiler-instrumented routines or user-instrumented routines.

Another possibility is not to record the whole application run. In many cases,
only parts of the application are of interest for analysis (e.g. a frequently
performed calculation) while other parts are of less interest (e.g., initialization
and finalization) for performance analysis. Or the calculation itself shows
iterative behavior, where recording of one iteration would be sufficient for
analysis. Restricting recording to one or multiple time intervals during
measurement would reduce the required space and overhead. This approach is called
selective recording.

@scorep provides two possibilities for selective recording.
<ul>
  <li> A configuration file can specify recorded regions. The entry and exit of those
       regions define an interval during which events are recorded. </li>
  <li> With user instrumentation, the recording can be manually switched on /off.
       (See Section @secref{manual_instrumentation}).
</ul>

Switching recording on or off, can result in inconsistent traces or profiles, if not
applied with care. Especially, switching recording on/off manually via
<tt>SCOREP_RECORDING_ON</tt> and <tt>SCOREP_RECORDING_OFF</tt> from the Score-P user
instrumentation macros is not recommended. Inconsistent traces may result in
errors or deadlocks during analysis, or show unusable data. The consistency is endangered
if:
<ul>
  <li> @openmp events are missing in one thread while other threads have them.
       Furthermore, the @openmp parallel region events are required if any event
       inside a parallel region is recorded. To prevent inconsistencies from
       incomplete recording of @openmp events, it is not possible to switch
       recording on/off from inside a parallel region </li>
  <li> @mpi a communication is only recorded partially, e.g. if a send is missing, but
       the corresponding receive on another process is recorded. To ensure recording
       of complete communication is the responsibility of the user.
  <li> enter/exit events are not correctly nested. </li>
</ul>

How recording can be controlled through @scorep macros which are inserted in the
application's source code, is explained in
Section @secref{manual_instrumentation}. Thus, this section focuses on first
possibility, where the user specify recorded regions via a configuration file.
Selective recording affects tracing and profiling.

For selective recording, you can specify one or multiple traced regions. The
recording is enabled when a recorded region is entered. If the region is exited,
recording of events is switched off again. If a recorded region is called inside
another recorded region, thus, the recording is already enabled, it will not disable
recording of it exits, but recording will be switched off, if all recorded regions are
exited.

For recorded regions only regions from @scorep user instrumentation can be selected.
If regions from other instrumentation methods are specified in the configuration
file for selective recording, they are ignored.

For a recorded region, the recording can be restricted to certain executions of that
region. Therefor, the enters for a recorded region are counted, and a particular
execution can be specified by the number of its enter. If a recorded region is called
recursively, the recording is only switched off, if the exit is reached, that
corresponds to the enter that enabled recording.

The configuration file is a simple text file, where every line contains the name of
exactly one region. Optionally, a
comma-separated list of execution numbers or intervals of execution numbers can be
specified. A configuration file could look like follows:
@code
    foo
    bar 23:25, 50, 60:62
    baz 1
@endcode
This configuration file would record all executions of foo, the executions 23, 24, 25,
50, 60, 61, and 62 of bar, and the second (numbering starts with 0) execution of baz.

To apply the selective recording configuration file to a measurement run of your
application, set the environment variable \confvar{SCOREP_SELECTIVE_CONFIG_FILE}
to the configuration file and run your instrumented application. If
\confvar{SCOREP_SELECTIVE_CONFIG_FILE} is empty, or the given file cannot be opened,
the whole application run will be recorded (no selective recording will apply).


@section rewind Trace Buffer Rewind

Introducing a long-term event-trace recording mode, the trace
buffer rewind feature allows to discard the preceding section of the event trace at certain control points
or phase markers. The live decision whether to keep or discard a section can depend on the
presence or absence of certain behaviour patterns as well as on similarity or difference
with other sections.

Based on user regions (see @secref{manual_instrumentation}), three macros are given which control the rewind. These are:

@code
  // to define a local region handle based on the function
  // SCOREP_USER_REGION_DEFINE( ... )
SCOREP_USER_REWIND_DEFINE( regionHandle )
  // similar to SCOREP_USER_REGION_BEGIN( ... )
SCOREP_USER_REWIND_POINT( regionHandle, "name" )
  // similar to SCOREP_USER_REGION_END( ... )
  // w/ additional parameter to control the rewind (yes or no)
SCOREP_USER_REWIND_CHECK( regionHandle, boolean )
@endcode

The user has to specify whether or not a rewind is requested with a boolean variable in the SCOREP_USER_REWIND_CHECK function.
There are two different approaches what to do with the rewind region in the trace based on the boolean variable.
If the boolean variable is true,
the trace buffer will be reset to an old snapshot and after that rewind
region enter and leave events will be written into the trace buffer to mark the presence
of the trace buffer rewind. This rewind region then looks like a normal user-defined region
in the trace. If the variable is false, than no events of the rewind region are written into
the trace, so that the trace buffer looks like the user never instrumented the code w/ rewind
regions. Trace buffer
flushes have an impact on the rewind regions, i.e. if a flush occurs all previous stored
rewind points (which are not "checked", i.e. the flush is in between the region) will be
deleted and the SCOREP_USER_REWIND_CHECK function won't write the enter/leave events into the
trace independently from the boolean variable. Wrong nested rewind regions are handled as follows:

@code
SCOREP_USER_REWIND_POINT( point 1, ...);
... do stuff ...
SCOREP_USER_REWIND_POINT( point 2, ...);
... do stuff ...
SCOREP_USER_REWIND_CHECK( point 1, true );
... do stuff ...
SCOREP_USER_REWIND_CHECK( point 2, true );
@endcode

The check for point 2 would corrupt the trace buffer, so point 2 would be deleted and
ignored in the second check.


@subsection mpi_groups Selection of MPI Groups
@seclabel{mpi_groups}

The Message Passing Interface (MPI) adapter of @scorep supports the tracing
of most of MPI's 300+ function calls. MPI defines a so-called 'profiling
interface' that supports the provision of wrapper libraries that can
easily interposed between the user application and the MPI library
calls.

The general @scorep filtering mechanism is not applied to MPI functions. Instead,
the user can decide whether event generation is turned on or off for a group of
@mpi functions, at start time of the application. These groups
are the listed sub-modules of this adapter. Each module has a short
string token that identifies this group. To activate event generation
for a specific group, the user can specify a comma-separated list of
tokens in the configuration variable \confvar{SCOREP_MPI_ENABLE_GROUPS}. Additionally,
special tokens exist to ease the handling by the user. A complete list
of available tokens that can be specified in the runtime configuration
is listed below.

@latexonly
\begin{table}
@endlatexonly
<table>
<tr>
 <th>Token</th><th>Module</th>
</tr>
<tr>
 <td>ALL</td><td>Activate all available modules</td>
</tr>
<tr>
 <td>DEFAULT</td><td>Activate the configured default modules of CG, COLL, ENV, IO, P2P, RMA, TOPO, XNONBLOCK. This can
 be used to easily activate additional modules.</td>
</tr>
<tr>
 <td>CG</td><td>Communicators and groups</td>
</tr>
<tr>
 <td>COLL</td><td>Collective communication</td>
</tr>
<tr>
 <td>ENV</td><td>Environmental management</td>
</tr>
<tr>
 <td>ERR</td><td>Error handlers</td>
</tr>
<tr>
 <td>EXT</td><td>External interfaces</td>
</tr>
<tr>
 <td>IO</td><td>I/O</td>
</tr>
<tr>
 <td>MISC</td><td>Miscellaneous</td>
</tr>
<tr>
 <td>P2P</td><td>Point-to-point communication</td>
</tr>
<tr>
 <td>RMA</td><td>One-sided communication</td>
</tr>
<tr>
 <td>SPAWN</td><td>Process management interface (aka Spawn)</td>
</tr>
<tr>
 <td>TOPO</td><td>Topology communicators</td>
</tr>
<tr>
 <td>TYPE</td><td>MPI Datatypes</td>
</tr>
<tr>
 <td>XNONBLOCK</td><td>Extended non-blocking communication events</td>
</tr>
<tr>
 <td>XREQTEST</td><td>Test events for tests of uncompleted requests</td>
</tr>
</table>
@latexonly
\end{table}
@endlatexonly

@note  Event generation in this context only relates to flow and
transfer events. Tracking of communicators, groups, and other internal
data is unaffected and always turned on.

Example:
<pre>
SCOREP_MPI_ENABLE_GROUPS=ENV,P2P
</pre>

This will enable event generation for environmental management, including
<tt>MPI_Init</tt> and <tt>MPI_Finalize</tt>, as well as point-to-point
communication, but will disable it for all other functions groups.

A shorthand to get event generation for all supported function calls is
<pre>
SCOREP_MPI_ENABLE_GROUPS=ALL
</pre>

A shorthand to add a single group, e.g. \p TYPE, to the configured default is
<pre>
SCOREP_MPI_ENABLE_GROUPS=DEFAULT,TYPE
</pre>

A detailed overview of the @mpi functions associated with each group can be
found in Appendix @secref{wrapperannex}.

A somehow special role plays the <tt>XNONBLOCK</tt> flag. This flag determines what kind
of events are generated by non-blocking peer-to-peer MPI function calls. If
<tt>XNONBLOCK</tt> is not set, an OTF2_MPI_Send event is created at the non-blocking send
call and an OTF2_MPI_Recv event is recorded when a non-blocking receive request has
completed.
If <tt>XNONBLOCK</tt> is set, an OTF2_Isend event is recorded at the
non-blocking send and an OTF2_IsendComplete event when the event was
completed. Furthermore, on a non-blocking receive, it records an
OTF2_IRecvRequest event. On request completion an OTF2_IRecv event is recorded.
In both cases the group <tt>P2P</tt> must be enabled. Otherwise @scorep records no
events for peer-to-peer communication functions.

@section mpi_comm_name Recording MPI Communicator Names
@seclabel{mpi_comm_name}

The measurement system tracks also the names of MPI communicators to easily
identify them later in the analysis. This is done via the
<tt>MPI_Comm_set_name</tt> call. But there are some restrictions. First, the
name of a communicator is only recorded at the first call to <tt>MPI_Comm_set_name</tt>
for this communicator. Later calls are ignored. Also this call is only
honored when the call was made from the rank which is rank 0 in this communicator.
Other calls from other ranks are ignored. And lastly the name will also be not
recorded if the communicator has only one member.


@section perf_counters Recording Performance Metrics
@seclabel{perf_metrics}

If @scorep has been built with performance metric support it is capable of recording performance counter information.
To request the measurement of certain counters, the user is required to set individual environment variables.
The user can leave these environment variables unset to indicate that no counters are requested.
Requested counters will be recorded with every enter/exit event.

@subsection papi_counters PAPI Hardware Performance Counters
@seclabel{papi_counters}

@scorep provides the possibility to query hardware performance counters and include these
metrics into the trace and/or profile. @scorep uses the
@href{http://icl.cs.utk.edu/papi/,Performance Application Programming Interface}
(PAPI) to access hardware performance counters.
Recording of PAPI performance counters is enabled by setting the environment variable \confvar{SCOREP_METRIC_PAPI} to a comma-separated list of counter names.
Counter names can be any PAPI preset names or PAPI native counter names.

Example:
<pre>
SCOREP_METRIC_PAPI=PAPI_FP_OPS,PAPI_L2_TCM
</pre>

This will record the number of floating point instructions and level 2 cache misses.
If any of the requested counters is not recognized, program execution will be aborted with an error message.
The PAPI utility programs <tt>papi_avail</tt> and <tt>papi_native_avail</tt> report information about the counters available on the current platform.

If you want to change the separator used in the list of PAPI counter names, set the environment variable \confvar{SCOREP_METRIC_PAPI_SEP} to the desired character.

@note
In addition it is possible to specify metrics that will be recorded only by the initial thread of a process. Please use \confvar{SCOREP_METRIC_PAPI_PER_PROCESS} for that reason.

@subsection rusage_counters Resource Usage Counters
@seclabel{rusage_counters}

Besides PAPI, Resource Usage Counters can be recorded.
These metrics use the Unix system call <tt>getrusage</tt> to provide information about consumed resources and operating system events such as user/system time, received signals, and number of page faults.
The manual page of <tt>getrusage</tt> provides a list of resource usage counters.
Please note that the availability of specific counters depends on the operating system.

You can enable recording of resource usage counters by setting the \confvar{SCOREP_METRIC_RUSAGE} environment variable.
The variable should contain a comma-separated list of counter names.

Example:
<pre>
SCOREP_METRIC_RUSAGE=ru_utime,ru_stime
</pre>

This will record the consumed user time and system time.
If any of the requested counters is not recognized, program execution will be aborted with an error message.

@note Please be aware of the scope of displayed resource usage statistics.
@scorep records resource usage statistics for each individual thread, if the output while configuring your @scorep installation contains something like
<pre>
RUSAGE_THREAD support: yes
</pre>
Otherwise, the information displayed is valid for the whole process.
That means, for multi-threaded programs the information is the sum of resources used by all threads in the process.


A shorthand to record all resource usage counters is
<pre>
SCOREP_METRIC_RUSAGE=all
</pre>
However, this is not recommended as most operating systems does not support all metrics.

If you want to change the separator used in the list of resource usage metrics, set the environment variable \confvar{SCOREP_METRIC_RUSAGE_SEP} to the desired character.

Example:
<pre>
SCOREP_METRIC_RUSAGE_SEP=:
</pre>
This indicates that counter names in the list are separated by colons.

@note
In addition it is possible to specify metrics that will be recorded only by the initial thread of a process. Please use \confvar{SCOREP_METRIC_RUSAGE_PER_PROCESS} for that reason.

@subsection metric_perf Recording Linux Perf Metrics

This metric source uses the Linux Perf Interface to access hardware performance counters.
First it is explained how to specify PERF metrics that will be recorded by every location.

You can enable the recording of PERF performance metrics by setting the environment variable \confvar{SCOREP_METRIC_PERF} to a comma-separated list of metric names.
Metric names can be any PERF preset names or PAPI native counter names.

Example:
<pre>
SCOREP_METRIC_PERF=cycles,page-faults,LLC-load-misses
</pre>

In this example the number of CPU cycles, the number of page faults, and Last Level Cache Load Misses will be recorded.
If any of the requested metrics is not recognized program execution will be aborted with an error message.
The user can leave the environment variable unset to indicate that no metrics are requested.
Use the tool <tt>perf list</tt> to get a list of available PERF events.

If you want to change the separator used in the list of PERF metrics, set the environment variable \confvar{SCOREP_METRIC_PERF_SEP} to the desired character.

Example:
<pre>
SCOREP_METRIC_PERF_SEP=:
</pre>
This indicates that counter names in the list are separated by colons.

@note
In addition it is possible to specify metrics that will be recorded per-process.
Please use \confvar{SCOREP_METRIC_PERF_PER_PROCESS} for that reason.

@subsection metric_plugins Metric Plugins

Metric plugins extend the functionality of @scorep by providing additional counters as external libraries.
The libraries are loaded when tracing or profiling your application.
So there is no need to recompile your application or instrument it manually.

A simple example of a synchronous metric plugin can be found in Appendix @secref{metricpluginexample}.
Every plugin needs to include SCOREP_MetricPlugins.h.
The commands to build the corresponding library of this plugin might look like:

@code
gcc -c -fPIC hello_world.c   \
    -o libHelloWorld_plugin.so.o `scorep-config --cppflags`
gcc -shared -Wl,-soname,libHelloWorld_plugin.so  \
    -o libHelloWorld.so libHelloWorld_plugin.so.o
@endcode

To enable a metric plugin, add the plugin <PLUGINNAME> to the environment variable \confvar{SCOREP_METRIC_PLUGINS} and configure the used metrics through the environment variable SCOREP_METRIC_PLUGINNAME.
In the following example we want to use the above <tt>HelloWorld</tt> plugin.
We select two counters <tt>metric1</tt> and <tt>metric2</tt> from the plugin.
Make sure that the metric plugin library is placed in a directory which is part of <tt>LD_LIBRARY_PATH</tt>.

<pre>
SCOREP_METRIC_PLUGINS=HelloWorld_plugin
SCOREP_METRIC_HELLOWORLD_PLUGIN=metric1,metric2
</pre>

@note Plugins are not supposed to trigger events (e.g. via @mpi, @openmp, Pthreads or user instrumentation) during initialization and finalization of the plugin.
@note A set of open source metric plugins is available at <a href="https://github.com/score-p">GitHub</a>.

@section cuda_adapter CUDA Performance Measurement
@seclabel{cuda_adapter}

If @scorep has been built with CUDA support it is capable of recording CUDA API function calls and GPU activities. The measurement is based on NVIDIA's <b>CU</b>DA <b>P</b>rofiling and <b>T</b>ool <b>I</b>nterface (CUPTI), which is an integral part of the CUDA Toolkit since version 4.1.

@scorep can wrap the NVIDIA compiler (<b><tt>scorep nvcc</tt></b>) to instrument .cu files. If @scorep has been built with the Intel compiler an additional flag has to be added for instrumentation:

 <tt>--compiler-bindir=<path-to-intel-compiler-command></tt>

 Otherwise the program will not be instrumented, as <tt>nvcc</tt> uses the GNU compiler by default.

Setting the environment variable \confvar{SCOREP_CUDA_ENABLE} to <b><tt>yes</tt></b> enables CUDA measurement.
Please refer to the description of this variable to enable a particular composition of CUDA measurement features.

CUPTI uses an extra buffer to store its activity records.
If the size of this buffer is too small, @scorep will print a warning about the current buffer size and the number of dropped records.
To avoid dropping of records increase the buffer size via the environment variable \confvar{SCOREP_CUDA_BUFFER} (default: 1M).

Since CUDA toolkit version 5.5 the chunk size for the CUPTI activity buffer can be specified via the environment variable \confvar{SCOREP_CUDA_BUFFER_CHUNK} (default: 8k). Buffer chunks are allocated whenever CUPTI requests a buffer (e.g. to record activities on a CUDA stream).
\confvar{SCOREP_CUDA_BUFFER} specifies the upper bound of memory to be allocated for CUPTI activities. Therefore it should be a multiple of \confvar{SCOREP_CUDA_BUFFER_CHUNK}.

@note Make sure to call <tt>cudaDeviceReset()</tt> or <tt>cudaDeviceSynchronize()</tt> before the exit of the program. Otherwise GPU activities might be missing in the trace.

@note For CUDA 5.5 there is an error in CUPTI buffer handling. The last activity in a CUPTI activity buffer (\confvar{SCOREP_CUDA_BUFFER_CHUNK}) gets lost, when the buffer is full.
To avoid this issue specify \confvar{SCOREP_CUDA_BUFFER_CHUNK} as large as necessary to store all CUDA device activities until the CUDA device is synchronized with the host.
In CUDA 6.0 this issue is fixed and CUPTI does not request buffers for individual streams any more.

@note @scorep supports CUDA monitoring since CUDA toolkit version 4.1. Make sure that the @scorep installation has configured CUDA support. The configure summary should contain the line:
<pre>CUDA support: yes</pre>
If not, for most systems it is sufficient to specify the CUDA toolkit directory at @scorep configuration time:
<pre> --with-libcudart=<path-to-cuda-toolkit-directory></pre>
Otherwise check the configure help output to specify the location of the CUDA toolkit and CUPTI libraries and include files:
<pre> ./configure --help=recursive | grep -E "(cuda|cupti)"</pre>

CUDA device and host activities can be filtered by name at runtime using the @scorep filter file (see Section @secref{filtering}).
Filtering does not remove CUDA activities inserted by @scorep or CUDA data transfers inserted as RDMA events.
If a kernel is filtered, no kernel launch properties activated in \confvar{SCOREP_CUDA_ENABLE} using <tt>kernel_counter</tt> are inserted for this kernel.
GPU idle time is not affected by kernel filtering.


@section opencl_adapter OpenCL Performance Measurement
@seclabel{opencl_adapter}

If @scorep has been built with OpenCL support it is capable of recording OpenCL API function calls.

Setting the environment variable \confvar{SCOREP_OPENCL_ENABLE} to <b><tt>yes</tt></b> enables OpenCL measurement.
Please refer to the description of this variable to enable a particular composition of OpenCL measurement features.

OpenCL measurement uses an extra buffer to store its activity records.
If the size of this buffer is too small, @scorep will print a warning about the current buffer size and the number of dropped records.
To avoid dropping of records increase the buffer size via the environment variable \confvar{SCOREP_OPENCL_BUFFER} (default: 1M).
Memory in bytes for the OpenCL command queue buffer can be adjusted by setting the environment variable \confvar{SCOREP_OPENCL_BUFFER_QUEUE} (default: 8k).


@section online_access_measurement Online Access Interface
@seclabel{online_access_measurement}

Online Access (OA) is an interface to the measurement system of @scorep allowing online analysis capable tools to
configure and retrieve profile measurements remotely over sockets.

The Online Access interface implements a client-server paradigm, where @scorep acts as a server accepting connections
from the remote tool. During the initialization, the OA module of the @scorep creates one socket for each application
process. The network addresses and the ports of these sockets are published at the registry service
and could be later queried by the remote tool. The hostname and the port of the registry service should be specified
via the \confvar{SCOREP_ONLINEACCESS_REG_HOST} and \confvar{SCOREP_ONLINEACCESS_REG_PORT} environment variables, respectively. After publishing the socket
addresses and ports, the OA module will accept connections. Once the connection is established the OA module will suspend the
application execution and wait for requests. The format of the requests is plain text following the syntax below:

@code
<request>              = <metric_configuration> | <execution> | <retrieval>
<metric_configuration> = BEGINREQUESTS GLOBAL <request_type>
                         ENDREQUESTS
<request_type>         = MPI | EXECUTION_TIME |
                         METRIC <metric_specification>
<metric_specification> = PERISCOPE <periscope_metric_code> |
                         PAPI "<papi_counter_name>" |
                         RUSAGE "<rusage_metric_name>" |
                         OTHER "metric_name"
<execution>            = TERMINATE | RUNTOSTART | RUNTOEND
<retrieval>            = GETSUMMARYDATA
@endcode

where
<ul>
 <li>
    <tt>BEGINREQUESTS</tt> indicates the beginning of the request list,
 </li>
 <li>
    <tt>ENDREQUESTS</tt> indicates the end of the request list,
 </li>
 <li>
    <tt>GLOBAL</tt> indicates that the following measurement request is applied to all locations,
 </li>
 <li>
    <tt>MPI</tt> requests mpi wait states analysis,
 </li>
 <li>
    <tt>EXECUTION_TIME</tt> requests execution time,
 </li>
  <li>
    <tt>METRIC</tt> indicates the begin of the metric request,
 </li>
 <li>
    <tt>PERISCOPE <periscope_metric_code></tt> requests a metric by the Periscope internal code,
 </li>
 <li>
    <tt>PAPI <papi_counter_name></tt> requests a PAPI hardware counter metric by the counter name,
 </li>
 <li>
    <tt>RUSAGE <rusage_counter_name></tt> requests a Resource Usage Counter metric by the counter name,
 </li>
 <li>
    <tt>OTHER <metric_name></tt> requests a metric, to be defined in @scorep definition system, specified by the name,
 </li>
 <li>
    <tt>TERMINATE</tt> requests termination of the application,
 </li>
 <li>
    <tt>RUNTOSTART</tt> requests @scorep to run the beginning of the OA phase,
 </li>
 <li>
    <tt>RUNTOEND</tt> requests @scorep to run the end of the OA phase,
 </li>
 <li>
    <tt>GETSUMMARYDATA</tt> requests retrieval of the profile data.
 </li>
</ul>

When the <tt>GETSUMMARY</tt> request is received, the OA module will transform the call-path profile into a  flat profile and send
the data back to the remote tool. The flat profile is sent in two parts, where the first part carries the region
definition data and the second part carries profile measurements. Each part starts with the key word <tt>MERGED_REGION_DEFINITIONS</tt>
or <tt>FLAT_PROFILE</tt> and followed by the number of the entries and the buffer containing the data.

*/

/**
 * @file  SCOREP_Mpi_P2p.c
 * @maintainer Daniel Lorenz <d.lorenz@fz-juelich.de>
 * @status     alpha
 * @ingroup    MPI_Wrapper
 *
 * @brief C interface wrappers for point-to-point communication
 */

#include <config.h>
#include "SCOREP_Mpi.h"

/**
 * @name Blocking
 * @{
 */
#pragma wrapgen multiple regex(MPI_(S|B|R)[s]?end$) skel/SCOREP_Mpi_PtpSend.w

#if HAVE(DECL_PMPI_RECV) && !defined(SCOREP_MPI_NO_P2P)
/** 
 * Measurement wrapper for MPI_Recv
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Sequence of events:
 * @li enter region 'MPI_Recv'
 * @li MPI recv event
 * @li exit region 'MPI_Recv'
 */
int MPI_Recv( void* buf,
              int count,
              MPI_Datatype datatype,
              int source, int tag,
              MPI_Comm comm,
              MPI_Status* status )
{
  int return_val;

  if (SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P))
  {
    int        sz;
    uint64_t start_time_stamp;
    MPI_Status mystatus;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_RECV]);

    #if ! defined(SCOREP_MPI_NO_HOOKS)
      if(SCOREP_IS_MPI_HOOKS_ON)
        start_time_stamp = SCOREP_GetLastTimeStamp();
    #endif

    if (status == MPI_STATUS_IGNORE) status = &mystatus;
    return_val = PMPI_Recv(buf, count, datatype, source, tag, comm, status);

    #if ! defined(SCOREP_MPI_NO_HOOKS)
      if(SCOREP_IS_MPI_HOOKS_ON)
        SCOREP_Hooks_Post_MPI_Recv(buf, count, datatype, source, tag, comm, status, start_time_stamp, return_val);
    #endif
 
    if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
    {
      PMPI_Type_size(datatype, &sz);
      PMPI_Get_count(status, datatype, &count);
      SCOREP_MpiRecv(SCOREP_MPI_RANK_TO_PE(status->MPI_SOURCE, comm),
                   SCOREP_MPI_COMM_HANDLE(comm), status->MPI_TAG, count * sz);
    }



    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_RECV]);

    SCOREP_MPI_EVENT_GEN_ON();
  }
  else
  {
    return_val = PMPI_Recv(buf, count, datatype, source, tag, comm, status);
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Probe skel/SCOREP_Mpi_Std.w

#if HAVE(DECL_PMPI_SENDRECV) && !defined(SCOREP_MPI_NO_P2P)
/** 
 * Measurement wrapper for MPI_Sendrecv
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Sequence of events:
 * @li enter region 'MPI_Recv'
 * @li MPI send event
 * @li MPI recv event
 * @li exit region 'MPI_Recv'
 */
int MPI_Sendrecv(void* sendbuf,
                 int sendcount,
                 MPI_Datatype sendtype,
                 int dest,
                 int sendtag,
                 void* recvbuf,
                 int recvcount,
                 MPI_Datatype recvtype,
                 int source,
                 int recvtag,
                 MPI_Comm comm,
                 MPI_Status* status )
{
  int return_val;

  if (SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P))
  {
    int        sendsz, recvsz;
    MPI_Status mystatus;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_SENDRECV]);

    if (dest != MPI_PROC_NULL)
    {
      PMPI_Type_size(sendtype, &sendsz);
      SCOREP_MpiSend(SCOREP_MPI_RANK_TO_PE(dest, comm), SCOREP_MPI_COMM_HANDLE(comm),
                   sendtag, sendcount * sendsz);
    }

    if (status == MPI_STATUS_IGNORE)
    {
      status = &mystatus;
    }

    return_val = PMPI_Sendrecv(sendbuf, sendcount, sendtype, dest,   sendtag,
                           recvbuf, recvcount, recvtype, source, recvtag,
                           comm, status);
    if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
      {
        PMPI_Type_size(recvtype, &recvsz);
        PMPI_Get_count(status, recvtype, &recvcount);
        SCOREP_MpiRecv(SCOREP_MPI_RANK_TO_PE(status->MPI_SOURCE, comm),
                     SCOREP_MPI_COMM_HANDLE(comm), status->MPI_TAG, recvcount * recvsz);
      }

    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_SENDRECV]);

    SCOREP_MPI_EVENT_GEN_ON();
  }
  else
  {
    return_val = PMPI_Sendrecv(sendbuf, sendcount, sendtype, dest,   sendtag,
                           recvbuf, recvcount, recvtype, source, recvtag,
                           comm, status);
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_SENDRECV_REPLACE) && !defined(SCOREP_MPI_NO_P2P)
/** 
 * Measurement wrapper for MPI_Sendrecv_replace
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Sequence of events:
 * @li enter region 'MPI_Recv'
 * @li MPI send event
 * @li MPI recv event
 * @li exit region 'MPI_Recv'
 */
int MPI_Sendrecv_replace(void* buf,
                         int count,
                         MPI_Datatype datatype,
                         int dest,
                         int sendtag,
                         int source,
                         int recvtag,
                         MPI_Comm comm,
                         MPI_Status* status )
{
  int return_val;


  if (SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P))
  {
    int        sz;
    MPI_Status mystatus;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_SENDRECV_REPLACE]);

    PMPI_Type_size(datatype, &sz);
    if (dest != MPI_PROC_NULL)
    {
      SCOREP_MpiSend(SCOREP_MPI_RANK_TO_PE(dest, comm),
                   SCOREP_MPI_COMM_HANDLE(comm),
                   sendtag,
                   count * sz);
    }

    if (status == MPI_STATUS_IGNORE)
    {
      status = &mystatus;
    }
    
    return_val = PMPI_Sendrecv_replace(buf, count, datatype, dest,
                                   sendtag, source, recvtag,
                                   comm, status);
    if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
    {
      SCOREP_MpiRecv(SCOREP_MPI_RANK_TO_PE(status->MPI_SOURCE, comm),
                   SCOREP_MPI_COMM_HANDLE(comm), status->MPI_TAG, count * sz);
    }

    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_SENDRECV_REPLACE]);

    SCOREP_MPI_EVENT_GEN_ON();
  }
  else
  {
    return_val = PMPI_Sendrecv_replace(buf, count, datatype, dest,
                                   sendtag, source, recvtag,
                                   comm, status);
  }

  return return_val;
}
#endif

/**
 * @}
 * @name Non-blocking
 * @{
 */

#pragma wrapgen multiple regex(MPI_I(s|bs|rs|ss)end$) skel/SCOREP_Mpi_PtpIsend.w

#if HAVE(DECL_PMPI_IRECV) && !defined(SCOREP_MPI_NO_P2P)
/** 
 * Measurement wrapper for MPI_Irecv
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Irecv(void* buf,
              int count,
              MPI_Datatype datatype,
              int source,
              int tag,
              MPI_Comm comm,
              MPI_Request* request)
{
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int       return_val;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_IRECV]);
  }

  return_val = PMPI_Irecv(buf, count, datatype, source, tag, comm, request);
 
  if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
  {
    SCOREP_MpiRequestId reqid = scorep_mpi_get_request_id();
    int sz;
    PMPI_Type_size(datatype, &sz);

    if (event_gen_active && xnb_active)
      SCOREP_MpiRecvRequest(reqid);

    scorep_mpi_request_create(*request, SCOREP_MPI_REQUEST_RECV,
                       tag, 0, count * sz, datatype, comm, reqid);
  }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_IRECV]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Iprobe skel/SCOREP_Mpi_Std.w

#if HAVE(DECL_PMPI_WAIT) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Wait
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Wait(MPI_Request* request,
             MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  MPI_Status         mystatus;
  scorep_mpi_request* orig_req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAIT]);
  }

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }

  orig_req   = scorep_mpi_request_get(*request);
  return_val = PMPI_Wait(request, status);

  scorep_mpi_check_request(orig_req, status);

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAIT]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitall(int count,
                MPI_Request* requests,
                MPI_Status* array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  scorep_mpi_request* orig_req;
  int                 i;
  int                return_val;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITALL]);
  }

  if (array_of_statuses == MPI_STATUSES_IGNORE) 
  {
    array_of_statuses = scorep_get_status_array(count);
  }
  scorep_mpi_save_request_array(requests, count);

  return_val = PMPI_Waitall(count, requests, array_of_statuses);
  for (i = 0; i < count; i++)
  {
    orig_req = scorep_mpi_saved_request_get(i);
    scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
  }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITANY) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitany
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitany(int count,
                MPI_Request* requests,
                int* index,
                MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITANY]);
  }

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }

  scorep_mpi_save_request_array(requests, count);
  return_val = PMPI_Waitany(count, requests, index, status);

  if (event_gen_active && xnb_active)
    {
      int i;

      for (i = 0; i < count; ++i) {
        orig_req = scorep_mpi_saved_request_get(i);

        if (i == *index)
          scorep_mpi_check_request(orig_req, status);
        else if (orig_req)
          SCOREP_MpiRequestTested(orig_req->id);
      }
    }
  else
    {
      orig_req   = scorep_mpi_saved_request_get(*index);
      scorep_mpi_check_request(orig_req, status);
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITANY]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITSOME) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitsome
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitsome(int incount,
                 MPI_Request *array_of_requests,
                 int *outcount,
                 int *array_of_indices,
                 MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                i;
  scorep_mpi_request* orig_req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITSOME]);
  }

  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    array_of_statuses = scorep_get_status_array(incount);
  }
  scorep_mpi_save_request_array(array_of_requests, incount);
  return_val = PMPI_Waitsome(incount, array_of_requests, outcount,
                         array_of_indices, array_of_statuses );
  if (event_gen_active && xnb_active)
    {
      int j, tmp, cur;
      MPI_Status tmpstat;

      cur = 0;

      for (i = 0; i < incount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(i);

          if (orig_req)
            {
              for (j = cur; j < *outcount && i != array_of_indices[j]; ++j)
                ;

              if (j < *outcount)
                {
                  tmpstat               = array_of_statuses[cur];
                  scorep_mpi_check_request(orig_req, &(array_of_statuses[cur]));
                  array_of_statuses[j]  = tmpstat;

                  tmp                   = array_of_indices[cur];
                  array_of_indices[cur] = array_of_indices[j];
                  array_of_indices[j]   = tmp;

                  ++cur;
                }
              else
                {
                  SCOREP_MpiRequestTested(orig_req->id);
                }
            }
        }
    }
  else
    {
      for (i=0; i<*outcount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(array_of_indices[i]);
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITSOME]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TEST) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Test
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Test(MPI_Request* request,
             int* flag,
             MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TEST]);
  }

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }
  orig_req   = scorep_mpi_request_get(*request);
  return_val = PMPI_Test(request, flag, status);
  if (*flag) 
    {
      scorep_mpi_check_request(orig_req, status);
    }
  else if (orig_req && event_gen_active && xnb_active)
    {
      SCOREP_MpiRequestTested(orig_req->id);
    }
  
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TEST]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTANY) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testany
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testany(int count,
                MPI_Request *array_of_requests,
                int *index,
                int *flag,
                MPI_Status *status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTANY]);
  }

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }
  scorep_mpi_save_request_array(array_of_requests, count);
  return_val = PMPI_Testany( count, array_of_requests, index, flag, status );

  if (event_gen_active && xnb_active)
    {
      int i;

      for (i = 0; i < count; ++i) {
        orig_req = scorep_mpi_saved_request_get(i);

        if (*index == i)
          scorep_mpi_check_request(orig_req, status);
        else if (orig_req)
          SCOREP_MpiRequestTested(orig_req->id);
      }
    }
  else if (*flag && *index != MPI_UNDEFINED)
    {
      orig_req = scorep_mpi_saved_request_get(*index);
      scorep_mpi_check_request(orig_req, status);
    }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTANY]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testall(int count,
                MPI_Request *array_of_requests,
                int *flag,
                MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                i;
  scorep_mpi_request* orig_req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTALL]);
  }

  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    array_of_statuses = scorep_get_status_array(count);
  }
  scorep_mpi_save_request_array(array_of_requests, count);

  return_val = PMPI_Testall(count, array_of_requests, flag, array_of_statuses);

  if (*flag)
    {
      for (i = 0; i < count; i++)
        {
          orig_req = scorep_mpi_saved_request_get(i);
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }
  else if (event_gen_active && xnb_active)
    {
      int i;

      for (i = 0; i < count; i++)
        {
          orig_req = scorep_mpi_saved_request_get(i);
          if (orig_req)
            SCOREP_MpiRequestTested(orig_req->id);
        }
    }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTSOME) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testsome
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testsome(int incount,
                 MPI_Request *array_of_requests,
                 int *outcount,
                 int *array_of_indices,
                 MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                i;
  scorep_mpi_request* orig_req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTSOME]);
  }

  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    array_of_statuses = scorep_get_status_array(incount);
  }
  scorep_mpi_save_request_array(array_of_requests, incount);

  return_val = PMPI_Testsome( incount, array_of_requests, outcount,
                          array_of_indices, array_of_statuses );

  if (event_gen_active && xnb_active)
    {
      int cur, j, tmp;
      MPI_Status tmpstat;

      cur = 0;

      for (i=0; i<incount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(i);

          if (orig_req)
            {
              for (j = cur; j < *outcount && i != array_of_indices[j]; ++j)
                ;

              if (j < *outcount)
                {
                  tmpstat               = array_of_statuses[cur];
                  scorep_mpi_check_request(orig_req, &(array_of_statuses[cur]));
                  array_of_statuses[j]  = tmpstat;

                  tmp                   = array_of_indices[cur];
                  array_of_indices[cur] = array_of_indices[j];
                  array_of_indices[j]   = tmp;

                  ++cur;
                }
              else
                {
                  SCOREP_MpiRequestTested(orig_req->id);
                }
            }
        }
    }
  else
    {
      for (i=0; i<*outcount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(array_of_indices[i]);
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTSOME]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

/**
 * @}
 * @name Persitent requests
 * @{
 */

/* no asynchroneous communication handling at the beginning included 
pragma wrapgen multiple regex(MPI_(S|B|R)[s]?end_init$) skel/SCOREP_Mpi_PtpSendinit.w
*/
#pragma wrapgen multiple regex(MPI_(S|B|R)[s]?end_init$) skel/SCOREP_Mpi_Std.w

#if HAVE(DECL_PMPI_RECV_INIT) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Recv_init
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Recv_init(void* buf,
                  int count,
                  MPI_Datatype datatype,
                  int source,
                  int tag,
                  MPI_Comm comm,
                  MPI_Request* request)
{
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int       return_val;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_RECV_INIT]);
  }

  return_val = PMPI_Recv_init(buf, count, datatype, source, tag, comm, request);
  if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
  {
    int sz;
    PMPI_Type_size(datatype, &sz);
    scorep_mpi_request_create(*request, (SCOREP_MPI_REQUEST_RECV | SCOREP_MPI_REQUEST_IS_PERSISTENT),
                       tag, source, count * sz, datatype, comm,
                       scorep_mpi_get_request_id());
  }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_RECV_INIT]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_START) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Start
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Start(MPI_Request* request)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                return_val;

  if (event_gen_active)
  {
    scorep_mpi_request* req;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_START]);

    req = scorep_mpi_request_get(*request);
    if (req && (req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT))
      {
        req->flags |= SCOREP_MPI_REQUEST_IS_ACTIVE;
        if ((req->flags & SCOREP_MPI_REQUEST_SEND) && (req->dest != MPI_PROC_NULL))
          {
            if (xnb_active)
              SCOREP_MpiIsend(SCOREP_MPI_RANK_TO_PE(req->dest, req->comm),
                           SCOREP_MPI_COMM_HANDLE(req->comm), req->tag,  req->bytes, req->id);
            else
              SCOREP_MpiSend(SCOREP_MPI_RANK_TO_PE(req->dest, req->comm),
                           SCOREP_MPI_COMM_HANDLE(req->comm), req->tag,  req->bytes);
          }
        else if (req->flags & SCOREP_MPI_REQUEST_RECV && xnb_active)
          {
            SCOREP_MpiRecvRequest(req->id);
          }
      }
  }

  return_val = PMPI_Start(request);

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_START]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_STARTALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Startall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Startall(int count,
                 MPI_Request *array_of_requests)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                return_val, i;

  if (event_gen_active)
  {
    MPI_Request*       request;

    scorep_mpi_request* req;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_STARTALL]);

    for (i = 0; i < count; i++)
    {
      request = &array_of_requests[i];
      req     = scorep_mpi_request_get(*request);
      
      if (req && (req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT))
        {
          req->flags |= SCOREP_MPI_REQUEST_IS_ACTIVE;
          if ((req->flags & SCOREP_MPI_REQUEST_SEND) && (req->dest != MPI_PROC_NULL))
            {
              SCOREP_MpiIsend(SCOREP_MPI_RANK_TO_PE(req->dest, req->comm),
                           SCOREP_MPI_COMM_HANDLE(req->comm), req->tag,  req->bytes, req->id);
            }
          else if (req->flags & SCOREP_MPI_REQUEST_RECV && xnb_active)
            {
              SCOREP_MpiRecvRequest(req->id);
            }
        }

    }
  }

  return_val = PMPI_Startall( count, array_of_requests );

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_STARTALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_REQUEST_FREE) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Request_free
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Request_free( MPI_Request* request )
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                orig_req_null    = (*request == MPI_REQUEST_NULL);
  int                return_val;
  scorep_mpi_request* req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_REQUEST_FREE]);
  }

  req = scorep_mpi_request_get(*request);
  if (req)
    {
      if (req->flags & SCOREP_MPI_REQUEST_CAN_CANCEL && event_gen_active && xnb_active)
        {
          MPI_Status status;
          int        cancelled;
          /* -- Must check if request was cancelled and write the 
           *    cancel event. Not doing so will confuse the trace 
           *    analysis.
           */
          return_val = PMPI_Wait(request, &status);
          PMPI_Test_cancelled(&status, &cancelled);

          if (cancelled)
            SCOREP_MpiRequestCancelled(req->id);
        }

      if ((req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT) && (req->flags & SCOREP_MPI_REQUEST_IS_ACTIVE))
      {
        /* mark active requests for deallocation */
        req->flags |= SCOREP_MPI_REQUEST_DEALLOCATE;
      }
      else
      {
        /* deallocate inactive requests -*/
        scorep_mpi_request_free(req);
      }
    }

  /* -- We had to call PMPI_Wait for cancellable requests, which already
   *    frees (non-persistent) requests itself and sets them to 
   *    MPI_REQUEST_NULL. 
   *    As MPI_Request_free does not really like being called with 
   *    MPI_REQUEST_NULL, we have to catch this situation here and only 
   *    pass MPI_REQUEST_NULL if the application explicitely wanted that 
   *    for some reason.
   */
  if (*request != MPI_REQUEST_NULL || orig_req_null)
    return_val = PMPI_Request_free(request);


  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_REQUEST_FREE]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_CANCEL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Cancel
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Cancel( MPI_Request* request )
{
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int       return_val;
  scorep_mpi_request* req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_CANCEL]);
  }

  /* Mark request as cancellable and check for successful cancellation
   * on request completion or MPI_Request_free.
   * If XNONBLOCK is enabled, there will be a 'cancelled' event 
   * instead of a normal completion event in the trace, which can be
   * checked for by the trace analysis.
   */

  req = scorep_mpi_request_get(*request);

  if (req)
    req->flags |= SCOREP_MPI_REQUEST_CAN_CANCEL;

  return_val = PMPI_Cancel(request);

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_CANCEL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Test_cancelled skel/SCOREP_Mpi_Std.w

/**
 * @}
 * @name Auxiluary functions
 * @{
 */

#pragma wrapgen multiple regex((Buffer_attach|Buffer_detach)) skel/SCOREP_Mpi_Std.w

/**
 * @}
 */

